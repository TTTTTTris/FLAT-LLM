# FLAT-LLM
Official code for FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression
